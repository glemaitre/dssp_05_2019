{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.560687\n",
      "n_neighbors: 3, average score: 0.716758\n",
      "n_neighbors: 5, average score: 0.722878\n",
      "n_neighbors: 10, average score: 0.696346\n",
      "n_neighbors: 20, average score: 0.599843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lemaitre/Documents/code/toolbox/scikit-learn/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.023341\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.039498\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.064197\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.011390\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.000649\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.116216\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.071810\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.041240\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.084375\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.093870\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.500107\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.481659\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.174550\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.513598\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.649796\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.704553\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.582849\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.580703\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.661283\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.734882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested.\n",
    "\n",
    "To inspect training score on the different folds, the parameter ``return_train_score`` is set to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=0.000, test=-0.025), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.019, test=-0.018), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=(train=-0.001, test=-0.015), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=0.002, test=-0.023), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=-0.017, test=-0.015), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV]  C=0.001, gamma=0.01, score=(train=0.001, test=-0.013), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.011, test=-0.014), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=-0.007, test=-0.004), total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV]  C=0.001, gamma=0.1, score=(train=0.010, test=-0.005), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.009, test=-0.015), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=-0.009, test=-0.006), total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV]  C=0.001, gamma=1, score=(train=0.010, test=-0.007), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.002, test=-0.023), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=-0.016, test=-0.015), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV]  C=0.01, gamma=0.001, score=(train=0.001, test=-0.013), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.022, test=-0.002), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.005, test=0.010), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV]  C=0.01, gamma=0.01, score=(train=0.021, test=0.006), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.098, test=0.073), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.093, test=0.111), total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV]  C=0.01, gamma=0.1, score=(train=0.110, test=0.084), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.086, test=0.064), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.081, test=0.097), total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] . C=0.01, gamma=1, score=(train=0.103, test=0.073), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.024, test=0.000), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.007, test=0.012), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV]  C=0.1, gamma=0.001, score=(train=0.023, test=0.008), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.187, test=0.153), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.177, test=0.206), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV]  C=0.1, gamma=0.01, score=(train=0.190, test=0.149), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.534, test=0.497), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.511, test=0.587), total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV]  C=0.1, gamma=0.1, score=(train=0.534, test=0.484), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.525, test=0.493), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.484, test=0.551), total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .. C=0.1, gamma=1, score=(train=0.526, test=0.450), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.203, test=0.168), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.191, test=0.223), total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV]  C=1, gamma=0.001, score=(train=0.204, test=0.163), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.614, test=0.575), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.580, test=0.659), total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] . C=1, gamma=0.01, score=(train=0.618, test=0.568), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.702, test=0.646), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.657, test=0.738), total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .. C=1, gamma=0.1, score=(train=0.700, test=0.633), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.761, test=0.697), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.744, test=0.764), total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .... C=1, gamma=1, score=(train=0.762, test=0.707), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.606, test=0.569), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.577, test=0.662), total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV]  C=10, gamma=0.001, score=(train=0.619, test=0.566), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.668, test=0.611), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.619, test=0.695), total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV]  C=10, gamma=0.01, score=(train=0.671, test=0.580), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.703, test=0.645), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.664, test=0.731), total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] . C=10, gamma=0.1, score=(train=0.705, test=0.639), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.835, test=0.720), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.821, test=0.747), total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ... C=10, gamma=1, score=(train=0.806, test=0.760), total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426981198391153\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.017678</td>\n",
       "      <td>-0.015015</td>\n",
       "      <td>-0.019229</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>-0.018924</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.006734</td>\n",
       "      <td>0.008642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>-0.022896</td>\n",
       "      <td>-0.015115</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>-0.017052</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>19</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.016687</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>0.008542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>-0.013772</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>-0.007146</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.008290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>-0.015187</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>17</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>-0.008648</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.008567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>-0.022680</td>\n",
       "      <td>-0.014848</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>-0.016826</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>-0.016450</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.001100      0.000026         0.000772        0.000084   0.001   \n",
       "1       0.000727      0.000037         0.000565        0.000025   0.001   \n",
       "2       0.000782      0.000012         0.000564        0.000045   0.001   \n",
       "3       0.001089      0.000072         0.000978        0.000020   0.001   \n",
       "4       0.000951      0.000171         0.000734        0.000165    0.01   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}          -0.024993   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}          -0.022896   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}          -0.013772   \n",
       "3           1      {'C': 0.001, 'gamma': 1}          -0.015187   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}          -0.022680   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -0.017678          -0.015015        -0.019229        0.004219   \n",
       "1          -0.015115          -0.013146        -0.017052        0.004210   \n",
       "2          -0.004061          -0.004943        -0.007592        0.004385   \n",
       "3          -0.005727          -0.006728        -0.009214        0.004243   \n",
       "4          -0.014848          -0.012949        -0.016826        0.004212   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               20            0.000130           -0.018924   \n",
       "1               19            0.002142           -0.016687   \n",
       "2               16            0.010638           -0.007146   \n",
       "3               17            0.009269           -0.008648   \n",
       "4               18            0.002357           -0.016450   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0           -0.001409         -0.006734         0.008642  \n",
       "1            0.000629         -0.004639         0.008542  \n",
       "2            0.010233          0.004575         0.008290  \n",
       "3            0.009774          0.003465         0.008567  \n",
       "4            0.000814         -0.004426         0.008525  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.671485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.628927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.742698\n",
       "15       1           1         0.722520\n",
       "14       1         0.1         0.672337\n",
       "18      10         0.1         0.671485\n",
       "17      10        0.01         0.628927"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............... C=0.001, gamma=0.001, score=-0.116, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ................ C=0.001, gamma=0.01, score=-0.114, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ................. C=0.001, gamma=0.1, score=-0.104, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................... C=0.001, gamma=1, score=-0.105, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................ C=0.01, gamma=0.001, score=-0.113, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ................. C=0.01, gamma=0.01, score=-0.088, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................... C=0.01, gamma=0.1, score=0.032, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ..................... C=0.01, gamma=1, score=0.019, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ................. C=0.1, gamma=0.001, score=-0.085, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.130, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.526, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.516, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.141, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.671, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.809, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.880, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.692, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.758, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.816, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.924, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lemaitre/Documents/code/toolbox/scikit-learn/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided hyper-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-optimization of parameters was done up to now by giving some values to be tried. Usually, we could automatically generated those values (randomly or not) by using `RandomSearchCV` or `GridSearchCV`.\n",
    "\n",
    "We could do a little be better by trying some parameters which we could consider more probable to optimize our problem depending on the previous parameters which we used before.\n",
    "\n",
    "We will use `scikit-optimize` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y\n",
    ")\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# gradient boosted trees tend to do well on problems like this\n",
    "reg = GradientBoostingRegressor(\n",
    "    n_estimators=50, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7887311203387"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_depth': [3, 5, 8]}\n",
    "grid = GridSearchCV(reg, param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=50,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='auto', random_state=0,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 8],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.908220</td>\n",
       "      <td>0.789567</td>\n",
       "      <td>0.876714</td>\n",
       "      <td>0.858167</td>\n",
       "      <td>0.050184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035546</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.914676</td>\n",
       "      <td>0.807356</td>\n",
       "      <td>0.886615</td>\n",
       "      <td>0.869549</td>\n",
       "      <td>0.045445</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051424</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 150}</td>\n",
       "      <td>0.916367</td>\n",
       "      <td>0.809508</td>\n",
       "      <td>0.887306</td>\n",
       "      <td>0.871060</td>\n",
       "      <td>0.045112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.868910</td>\n",
       "      <td>0.796826</td>\n",
       "      <td>0.868689</td>\n",
       "      <td>0.844808</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056116</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.871558</td>\n",
       "      <td>0.797255</td>\n",
       "      <td>0.871235</td>\n",
       "      <td>0.846683</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.080136</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 150}</td>\n",
       "      <td>0.872287</td>\n",
       "      <td>0.797706</td>\n",
       "      <td>0.871967</td>\n",
       "      <td>0.847320</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050685</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 50}</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.758307</td>\n",
       "      <td>0.838443</td>\n",
       "      <td>0.811669</td>\n",
       "      <td>0.037733</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.111293</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 100}</td>\n",
       "      <td>0.838446</td>\n",
       "      <td>0.759179</td>\n",
       "      <td>0.839465</td>\n",
       "      <td>0.812364</td>\n",
       "      <td>0.037609</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.151521</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 150}</td>\n",
       "      <td>0.838451</td>\n",
       "      <td>0.759198</td>\n",
       "      <td>0.839470</td>\n",
       "      <td>0.812373</td>\n",
       "      <td>0.037602</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.031460      0.009781         0.000772        0.000089   \n",
       "1       0.035546      0.003253         0.000878        0.000185   \n",
       "2       0.051424      0.001847         0.000840        0.000010   \n",
       "3       0.031327      0.000717         0.000779        0.000058   \n",
       "4       0.056116      0.001112         0.000922        0.000030   \n",
       "5       0.080136      0.001975         0.001082        0.000046   \n",
       "6       0.050685      0.001044         0.000941        0.000109   \n",
       "7       0.111293      0.012525         0.001411        0.000086   \n",
       "8       0.151521      0.015859         0.001792        0.000177   \n",
       "\n",
       "  param_max_depth param_n_estimators                                 params  \\\n",
       "0               3                 50   {'max_depth': 3, 'n_estimators': 50}   \n",
       "1               3                100  {'max_depth': 3, 'n_estimators': 100}   \n",
       "2               3                150  {'max_depth': 3, 'n_estimators': 150}   \n",
       "3               5                 50   {'max_depth': 5, 'n_estimators': 50}   \n",
       "4               5                100  {'max_depth': 5, 'n_estimators': 100}   \n",
       "5               5                150  {'max_depth': 5, 'n_estimators': 150}   \n",
       "6               8                 50   {'max_depth': 8, 'n_estimators': 50}   \n",
       "7               8                100  {'max_depth': 8, 'n_estimators': 100}   \n",
       "8               8                150  {'max_depth': 8, 'n_estimators': 150}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.908220           0.789567           0.876714         0.858167   \n",
       "1           0.914676           0.807356           0.886615         0.869549   \n",
       "2           0.916367           0.809508           0.887306         0.871060   \n",
       "3           0.868910           0.796826           0.868689         0.844808   \n",
       "4           0.871558           0.797255           0.871235         0.846683   \n",
       "5           0.872287           0.797706           0.871967         0.847320   \n",
       "6           0.838257           0.758307           0.838443         0.811669   \n",
       "7           0.838446           0.759179           0.839465         0.812364   \n",
       "8           0.838451           0.759198           0.839470         0.812373   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.050184                3  \n",
       "1        0.045445                2  \n",
       "2        0.045112                1  \n",
       "3        0.033929                6  \n",
       "4        0.034951                5  \n",
       "5        0.035082                4  \n",
       "6        0.037733                9  \n",
       "7        0.037609                8  \n",
       "8        0.037602                7  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036985395289777"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 150}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Gaussian Processes to drive the hyper-parameters optimization. We need to give a range of data to use for each parameter that we want to optimize. In addition, we need to create the objective function which we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fd95b98ff090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInteger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muse_named_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The list of hyper-parameters we want to optimize. For each one we define the bounds,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "\n",
    "# The list of hyper-parameters we want to optimize. For each one we define the bounds,\n",
    "# the corresponding scikit-learn parameter name, as well as how to sample values\n",
    "# from that dimension (`'log-uniform'` for the learning rate)\n",
    "space  = [Integer(1, 5, name='max_depth'),\n",
    "          Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(1, n_features, name='max_features'),\n",
    "          Integer(2, 100, name='min_samples_split'),\n",
    "          Integer(1, 100, name='min_samples_leaf')]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set scikit-learn\n",
    "# estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    reg.set_params(**params)\n",
    "\n",
    "    return -np.mean(cross_val_score(reg, X, y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_absolute_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those steps performed, we need to call the the optimization loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best score=3.1467'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "res_gp = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the best parameters obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "- max_depth=1\n",
      "- learning_rate=0.194488\n",
      "- max_features=7\n",
      "- min_samples_split=100\n",
      "- min_samples_leaf=13\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "- max_depth=%d\n",
    "- learning_rate=%.6f\n",
    "- max_features=%d\n",
    "- min_samples_split=%d\n",
    "- min_samples_leaf=%d\"\"\" % (res_gp.x[0], res_gp.x[1], \n",
    "                            res_gp.x[2], res_gp.x[3], \n",
    "                            res_gp.x[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can check the objective function values depending of the number of time we are calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "plot_convergence(res_gp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment on the original toy data and try to automatically optimize the parameter `C` and `gamma` of a SVR classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
